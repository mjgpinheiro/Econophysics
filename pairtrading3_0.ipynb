{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjgpinheiro/Econophysics/blob/main/pairtrading3_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUkmMf_WU-BT",
        "outputId": "67b60cfb-82f6-4b47-d7fd-77705d8edc5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing forex pairs from 2023-01-01 to 2025-03-05\n",
            "YF.download() has changed argument auto_adjust default to True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  47 of 47 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading data: 'Adj Close'\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "# Define major and minor forex pairs\n",
        "forex_pairs = [\n",
        "    # Major pairs\n",
        "    'EURUSD=X', 'GBPUSD=X', 'USDJPY=X', 'USDCHF=X', 'AUDUSD=X', 'USDCAD=X', 'NZDUSD=X',\n",
        "    # Minor pairs\n",
        "    'EURGBP=X', 'EURJPY=X', 'EURCHF=X', 'EURAUD=X', 'EURCAD=X', 'EURNZD=X',\n",
        "    'GBPJPY=X', 'GBPCHF=X', 'GBPAUD=X', 'GBPCAD=X', 'GBPNZD=X',\n",
        "    'CHFJPY=X', 'AUDJPY=X', 'CADJPY=X', 'NZDJPY=X',\n",
        "    # Exotic pairs\n",
        "    'USDSEK=X', 'USDNOK=X', 'USDDKK=X', 'USDSGD=X', 'USDHKD=X',\n",
        "    'EURHUF=X', 'EURPLN=X', 'EURCZK=X', 'EURTRY=X', 'EURSEK=X',\n",
        "    'GBPSEK=X', 'GBPNOK=X', 'GBPDKK=X', 'GBPSGD=X', 'GBPHKD=X',\n",
        "    'AUDNZD=X', 'AUDCHF=X', 'AUDCAD=X', 'CADCHF=X', 'NZDCHF=X',\n",
        "    'SGDJPY=X', 'SEKJPY=X', 'NOKJPY=X', 'DKKJPY=X', 'ZARJPY=X'\n",
        "]\n",
        "\n",
        "def download_forex_data(pairs, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Download forex data from Yahoo Finance\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data = yf.download(pairs, start=start_date, end=end_date)['Adj Close']\n",
        "        data = data.fillna(method='ffill')\n",
        "        # Remove pairs with too many missing values\n",
        "        missing_threshold = len(data) * 0.1  # 10% missing data threshold\n",
        "        data = data.dropna(axis=1, thresh=missing_threshold)\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading data: {e}\")\n",
        "        return None\n",
        "\n",
        "def test_cointegration(pair1, pair2, data, significance_level=0.05):\n",
        "    \"\"\"\n",
        "    Test for cointegration between two forex pairs\n",
        "    Returns: (is_cointegrated, p_value, hedge_ratio, half_life)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Calculate the optimal hedge ratio using OLS\n",
        "        Y = data[pair1].values\n",
        "        X = data[pair2].values\n",
        "        X = np.vstack([X, np.ones(len(X))]).T\n",
        "        beta = np.linalg.lstsq(X, Y, rcond=None)[0][0]\n",
        "\n",
        "        # Calculate the spread\n",
        "        spread = data[pair1] - beta * data[pair2]\n",
        "\n",
        "        # Perform ADF test\n",
        "        result = adfuller(spread.dropna())\n",
        "        p_value = result[1]\n",
        "\n",
        "        # Calculate half-life of mean reversion\n",
        "        spread_lag = spread.shift(1)\n",
        "        spread_diff = spread - spread_lag\n",
        "        spread_lag = spread_lag.dropna()\n",
        "        spread_diff = spread_diff.dropna()\n",
        "\n",
        "        model = np.polyfit(spread_lag, spread_diff, 1)\n",
        "        half_life = -np.log(2) / model[0] if model[0] < 0 else np.inf\n",
        "\n",
        "        return (p_value < significance_level, p_value, beta, half_life)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in cointegration test for {pair1} and {pair2}: {e}\")\n",
        "        return (False, 1.0, 0, np.inf)\n",
        "\n",
        "def find_significant_pairs(data, significance_level=0.05):\n",
        "    \"\"\"\n",
        "    Find significantly cointegrated pairs and sort by p-value\n",
        "    \"\"\"\n",
        "    pairs = list(itertools.combinations(data.columns, 2))\n",
        "    significant_pairs = []\n",
        "\n",
        "    print(f\"\\nAnalyzing {len(pairs)} possible pairs...\")\n",
        "\n",
        "    for pair in pairs:\n",
        "        pair1, pair2 = pair\n",
        "        is_cointegrated, p_value, hedge_ratio, half_life = test_cointegration(\n",
        "            pair1, pair2, data, significance_level\n",
        "        )\n",
        "\n",
        "        if is_cointegrated and half_life != np.inf and half_life > 0:\n",
        "            significant_pairs.append({\n",
        "                'pair1': pair1.replace('=X', ''),\n",
        "                'pair2': pair2.replace('=X', ''),\n",
        "                'p_value': p_value,\n",
        "                'hedge_ratio': hedge_ratio,\n",
        "                'half_life': half_life\n",
        "            })\n",
        "\n",
        "    # Sort by p-value (strongest cointegration first)\n",
        "    return sorted(significant_pairs, key=lambda x: x['p_value'])\n",
        "\n",
        "def plot_pair_analysis(data, pair_info):\n",
        "    \"\"\"\n",
        "    Create detailed analysis plot for a pair\n",
        "    \"\"\"\n",
        "    pair1 = pair_info['pair1'] + '=X'\n",
        "    pair2 = pair_info['pair2'] + '=X'\n",
        "    hedge_ratio = pair_info['hedge_ratio']\n",
        "\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(15, 12))\n",
        "\n",
        "    # Plot 1: Normalized prices\n",
        "    norm1 = data[pair1] / data[pair1].iloc[0]\n",
        "    norm2 = data[pair2] / data[pair2].iloc[0]\n",
        "    ax1.plot(norm1, label=pair_info['pair1'], linewidth=1)\n",
        "    ax1.plot(norm2, label=pair_info['pair2'], linewidth=1)\n",
        "    ax1.set_title(f'Normalized Prices: {pair_info[\"pair1\"]} vs {pair_info[\"pair2\"]}')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Plot 2: Spread\n",
        "    spread = data[pair1] - hedge_ratio * data[pair2]\n",
        "    ax2.plot(spread, label='Spread', color='green', linewidth=1)\n",
        "    ax2.axhline(y=spread.mean(), color='r', linestyle='--', label='Mean')\n",
        "    ax2.axhline(y=spread.mean() + 2*spread.std(), color='gray', linestyle=':', label='+2σ')\n",
        "    ax2.axhline(y=spread.mean() - 2*spread.std(), color='gray', linestyle=':', label='-2σ')\n",
        "    ax2.set_title('Price Spread with Trading Bands')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    # Plot 3: Spread distribution\n",
        "    ax3.hist(spread, bins=50, density=True, alpha=0.7, color='green')\n",
        "    ax3.set_title('Spread Distribution')\n",
        "    ax3.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def main():\n",
        "    # Set time period\n",
        "    end_date = datetime.now().strftime('%Y-%m-%d')\n",
        "    start_date = '2023-01-01'  # One year of data\n",
        "\n",
        "    print(f\"Analyzing forex pairs from {start_date} to {end_date}\")\n",
        "\n",
        "    # Download data\n",
        "    data = download_forex_data(forex_pairs, start_date, end_date)\n",
        "\n",
        "    if data is not None:\n",
        "        # Find significant pairs\n",
        "        significant_pairs = find_significant_pairs(data)\n",
        "\n",
        "        # Display results\n",
        "        print(f\"\\nFound {len(significant_pairs)} significant pairs (p < 0.05):\")\n",
        "        print(\"\\nTop Cointegrated Pairs:\")\n",
        "        print(f\"{'Pair 1':<10} {'Pair 2':<10} {'P-Value':<10} {'Hedge Ratio':<12} {'Half-Life':<10}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        # Show top 10 pairs with lowest p-values\n",
        "        for pair in significant_pairs[:10]:\n",
        "            print(f\"{pair['pair1']:<10} {pair['pair2']:<10} {pair['p_value']:.4f}    {pair['hedge_ratio']:.4f}      {pair['half_life']:.1f}\")\n",
        "\n",
        "            # Create detailed analysis plot for top 5 pairs\n",
        "            if significant_pairs.index(pair) < 5:\n",
        "                fig = plot_pair_analysis(data, pair)\n",
        "                plt.show()\n",
        "\n",
        "        # Save results to CSV\n",
        "        results_df = pd.DataFrame(significant_pairs)\n",
        "        results_df.to_csv('forex_pairs_analysis.csv', index=False)\n",
        "        print(\"\\nDetailed results saved to 'forex_pairs_analysis.csv'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}